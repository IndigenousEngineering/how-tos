{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalizing & standardizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) normalization: \n",
    "\n",
    "scales all data to values between 0 and 1.\n",
    "\n",
    "you must know or be able to estimate the expected min and max values for your data.\n",
    "\n",
    "#### 2) standardization:\n",
    "\n",
    "rescales the data distribution so that the mean of all observations is 0, and the standard deviation is 1.\n",
    "\n",
    "you must know or be able to estimate your mean and standard dev.\n",
    "\n",
    "your data must fit a gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from standard python data processing libraries, numpy, pandas & sklearn\n",
    "\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalization\n",
    "\n",
    "scikit-learn's MinMaxScaler object fits the data in order to estimate the max and min, then scales the data when we call .transform()\n",
    "\n",
    "note: the MinMaxScaler object expects data to be presented as a matrix of size (rows, columns), so even if you use a numpy array (as i do here), make sure your data is reshaped into a matrix using .reshape(rows, columns) before attempting to fit the scaler.\n",
    "\n",
    "### example 1:\n",
    "normalization on some contrived data that makes it easy to see what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretend time sequence\n",
    "\n",
    "data = [100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100.0\n",
      "1    200.0\n",
      "2    300.0\n",
      "3    400.0\n",
      "4    500.0\n",
      "5    600.0\n",
      "6    700.0\n",
      "7    800.0\n",
      "8    900.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_series = Series(data)\n",
    "\n",
    "print(data_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### useful objects: sklearn's MinMaxScaler & pandas' Series\n",
    "\n",
    "to normalize this data we'll be using MinMaxScaler, a scikit-learn object. the MinMaxScaler object expects a matrix with rows and columns as input; otherwise it gets mad. pandas Series object has a number of useful attributes & methods, some of which come in handy here.\n",
    "\n",
    "we'll use attributes and/or methods attached to both of these objects (sklearn's MinMaxScaler & pandas' Series) to normalize the data.\n",
    "\n",
    "##### pandas' Series documentation: \n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html\n",
    "\n",
    "##### .reshape(): \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.Series.reshape.html\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
    "\n",
    "##### more on using .reshape in pandas Series: \n",
    "\n",
    "https://stackoverflow.com/questions/14390224/reshape-of-pandas-series\n",
    "\n",
    "##### sklearn's MinMaxScaler documentation: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas Series attribute\n",
    "# .values returns an ndarray type\n",
    "\n",
    "data_values = data_series.values\n",
    "\n",
    "# numpy method .reshape()\n",
    "# can only be called on .values\n",
    "\n",
    "data_array = data_values.reshape((len(data_values),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training the normalizer\n",
    "\n",
    "remember, a normalizer is itself a type of model. it has to be trained. the scikit-learn MinMaxScaler object follows the familiar scikit-learn model api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a MinMaxScaler object\n",
    "# feature_range will give all values between 0 and 1\n",
    "\n",
    "data_scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the normalizer to the data\n",
    "\n",
    "data_scaler = data_scaler.fit(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 900.000000\n",
      "max: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "original_max = data_scaler.data_max_\n",
    "\n",
    "original_min = data_scaler.data_min_\n",
    "\n",
    "print('min: %f' '\\n' 'max: %f' % (original_max, original_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "# feed in the Series array to the trained model\n",
    "\n",
    "data_normalized = data_scaler.transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   ]\n",
      " [0.125]\n",
      " [0.25 ]\n",
      " [0.375]\n",
      " [0.5  ]\n",
      " [0.625]\n",
      " [0.75 ]\n",
      " [0.875]\n",
      " [1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inverse transform\n",
    "\n",
    "once the data has been transformed, it's also possible to transform it back, using the inverse_transform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.]\n",
      " [200.]\n",
      " [300.]\n",
      " [400.]\n",
      " [500.]\n",
      " [600.]\n",
      " [700.]\n",
      " [800.]\n",
      " [900.]]\n"
     ]
    }
   ],
   "source": [
    "data_inversed = data_scaler.inverse_transform(data_normalized)\n",
    "\n",
    "print(data_inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 2:\n",
    "some slightly random-er data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71322554 0.32331002 0.14940009 0.27190708 0.76416523 0.05511729\n",
      " 0.54936922 0.12393065 0.861575   0.00812809]\n"
     ]
    }
   ],
   "source": [
    "# create some data\n",
    "# np.random.rand creates a specified number of data points with a normal distribution\n",
    "# between 0 and 1\n",
    "\n",
    "data = np.random.rand(10)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.713226\n",
      "1    0.323310\n",
      "2    0.149400\n",
      "3    0.271907\n",
      "4    0.764165\n",
      "5    0.055117\n",
      "6    0.549369\n",
      "7    0.123931\n",
      "8    0.861575\n",
      "9    0.008128\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# load as a pandas Series\n",
    "# pandas series must be 1d\n",
    "\n",
    "data_series = Series(data)\n",
    "\n",
    "print(data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for the MinMaxScaler to fit\n",
    "# get values, then reshape\n",
    "\n",
    "series_values = data_series.values\n",
    "series_values = series_values.reshape(len(series_values), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate then fit scaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "scaler = scaler.fit(series_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.008128, max: 0.861575\n"
     ]
    }
   ],
   "source": [
    "# check results: min & max?\n",
    "\n",
    "print('min: %f, max: %f' % (scaler.data_min_, scaler.data_max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82617611]\n",
      " [0.36930467]\n",
      " [0.16553109]\n",
      " [0.30907486]\n",
      " [0.88586312]\n",
      " [0.05505814]\n",
      " [0.63418254]\n",
      " [0.13568807]\n",
      " [1.        ]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# transform: where the actual normalization happens\n",
    "\n",
    "normalized_data = scaler.transform(series_values)\n",
    "\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71322554]\n",
      " [0.32331002]\n",
      " [0.14940009]\n",
      " [0.27190708]\n",
      " [0.76416523]\n",
      " [0.05511729]\n",
      " [0.54936922]\n",
      " [0.12393065]\n",
      " [0.861575  ]\n",
      " [0.00812809]]\n"
     ]
    }
   ],
   "source": [
    "# the process can be reversed: inverse the transform to get the original values back\n",
    "\n",
    "inversed_nrml = scaler.inverse_transform(normalized_data)\n",
    "\n",
    "print(inversed_nrml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) standardization\n",
    "\n",
    "something here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
