{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# padding and truncating\n",
    "\n",
    "because of the input requirements of neural nets, deep learning libraries expect a fixed-length vectorization of data. NN models involve a many matrix operations, and performing them efficiently depends on inputs that are all the same length.\n",
    "\n",
    "this can pose a problem for NLP purposes: words and phrases can be variable lengths.\n",
    "\n",
    "one solution is to \"pad\" the sequences with empty values so that they are the same length, but their overall value is unchanged.\n",
    "\n",
    "another solution is to truncate sequences to the same length, by removing values from either the beginning or end of sequences whose lengths are above the specified maximum.\n",
    "\n",
    "keras offers convenient ways to both truncate and pad variable length sequences, so they are ready for a deep learning model.\n",
    "\n",
    "## padding for sequences of variable length\n",
    "\n",
    "\n",
    "### pre-sequence padding vs post-sequence padding\n",
    "\n",
    "padding is adding empty, or \"dummy\" values to either the beginning or end of a sequence, in order to ensure it's the pre-set length. \n",
    "\n",
    "the keras default is to add null values to the beginning of the sequence; this is referred to as pre-sequence padding. \n",
    "\n",
    "post-sequence padding--adding empty values to the end of a sequence--is also possible by setting the pad_sequences() function's padding parameter to \"post\". \n",
    "\n",
    "the decision of whether to use pre- or post-sequence padding depends on the problem being modeled.\n",
    "\n",
    "## truncation\n",
    "\n",
    "### pre-sequence truncation vs post-sequence truncation\n",
    "\n",
    "keras doesn't have a truncation-specific function in its sequence preprocessing library. instead, truncation is accomplished using the maxlen parameter of the pad_sequences() function above.\n",
    "\n",
    "the default here again is to truncate the beginning of a sequence. post-sequence truncation can be done by setting the truncating parameter equal to 'post'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create some data. we'll make several sequences of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 4, 6, 8], [2, 4, 6], [2, 4]]\n"
     ]
    }
   ],
   "source": [
    "seq = [\n",
    "    [2, 4, 6, 8],\n",
    "    [2, 4, 6],\n",
    "    [2, 4]]\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-sequence padding\n",
    "\n",
    "(the keras default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 6 8]\n",
      " [0 2 4 6]\n",
      " [0 0 2 4]]\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "\n",
    "pre_seq_padded = pad_sequences(seq)\n",
    "\n",
    "# test\n",
    "\n",
    "print(pre_seq_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post-sequence padding\n",
    "\n",
    "change the pad_sequence function's 'padding' parameter to equal 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 4, 6, 8], [2, 4, 6], [2, 4]]\n"
     ]
    }
   ],
   "source": [
    "# back to the original set of sequences\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 6 8]\n",
      " [2 4 6 0]\n",
      " [2 4 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# set padding parameter to 'post'\n",
    "\n",
    "post_seq_padded = pad_sequences(seq, padding='post')\n",
    "\n",
    "# test\n",
    "\n",
    "print(post_seq_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see the zeroes added to the ends of each of the shorter rows in our dataframe. \n",
    "\n",
    "our dataset is now post-sequence padded.\n",
    "\n",
    "## truncation examples\n",
    "\n",
    "let's create more sequences to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_seq = [\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8,],\n",
    "    [1, 2, 3, 4, 5, 6, 7],\n",
    "    [1, 2, 3, 4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-sequence truncation\n",
    "\n",
    "we use the same pad_sequences() function, but this time set maxlen equal to 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6 7 8]\n",
      " [3 4 5 6 7]\n",
      " [2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# truncate using the pre-sequence default\n",
    "\n",
    "pre_seq_truncated = pad_sequences(long_seq, maxlen=5)\n",
    "\n",
    "# test\n",
    "\n",
    "print(pre_seq_truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rows in our set of sequences now begin with 4, 3, and 2 respectively, instead of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post-sequence truncation\n",
    "\n",
    "to truncate from the ends of sequences, we use pad_sequences() again, with the truncating parameter set to 'post'. maxlen is still set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 5]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# truncate from the ends of sequences using truncating='post'\n",
    "\n",
    "post_seq_truncated = pad_sequences(long_seq, maxlen=5, truncating='post')\n",
    "\n",
    "# test\n",
    "\n",
    "print(post_seq_truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each row has had values removed from its end, truncating each at 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## that's it for sequence padding & truncation in keras (for now)\n",
    "\n",
    "there are of course ways to do this manually in python, which means you can adapt these basic ideas to suit your specific needs (or data!). when you don't need or want a custom implementation, keras offers a handy, quick way to prepare sequences for DL models.\n",
    "\n",
    "\n",
    "##### for more information about keras pre-processing:\n",
    "\n",
    "https://keras.io/preprocessing/sequence/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
